---
layout: post
title: "LangGraph Project 3: AI Agent cÆ¡ báº£n"
date: 2025-02-12
categories: [LangGraph, Project]
tags: [AI, LangGraph, LangChain, Gemini]
---

HÃ´m nay mÃ¬nh sáº½ chia sáº» vá»›i cÃ¡c báº¡n má»™t dá»± Ã¡n thÃº vá»‹ mang tÃªn **"Dá»± Ã¡n 3: XÃ¢y dá»±ng AI Agent Ä‘Æ¡n giáº£n"**. Trong bÃ i viáº¿t nÃ y, chÃºng ta sáº½ cÃ¹ng nhau tÃ¬m hiá»ƒu cÃ¡ch táº¡o ra má»™t Agent trÃ­ tuá»‡ nhÃ¢n táº¡o (AI Agent) cÃ³ kháº£ nÄƒng gá»i tool bÃªn ngoÃ i báº±ng cÃ¡ch sá»­ dá»¥ng má»™t sá»‘ thÆ° viá»‡n mÃ£ nguá»“n má»Ÿ nhÆ° **LangChain**, **LangGraph** vÃ  **Google Generative AI**. HÃ£y cÃ¹ng khÃ¡m phÃ¡ tá»«ng bÆ°á»›c trong quÃ¡ trÃ¬nh xÃ¢y dá»±ng vÃ  cháº¡y workflow cá»§a dá»± Ã¡n nhÃ©!

---

## 1. CÃ i Ä‘áº·t thÆ° viá»‡n ğŸš€

Äáº§u tiÃªn, chÃºng ta cáº§n cÃ i Ä‘áº·t má»™t sá»‘ thÆ° viá»‡n cáº§n thiáº¿t. Äoáº¡n code dÆ°á»›i Ä‘Ã¢y giÃºp cÃ i Ä‘áº·t cÃ¡c package nhÆ° `langchain`, `langchain_core`, `langchain_community`, `langchain_google_genai` vÃ  `langgraph` má»™t cÃ¡ch nhanh chÃ³ng:

```bash
!pip install langchain langchain_core langchain_community -q
!pip install langchain_google_genai -q
!pip install langgraph -q
```

Viá»‡c cÃ i Ä‘áº·t nÃ y Ä‘áº£m báº£o mÃ´i trÆ°á»ng cá»§a báº¡n cÃ³ Ä‘áº§y Ä‘á»§ cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ triá»ƒn khai Agent vÃ  lÃ m viá»‡c vá»›i cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ tiÃªn tiáº¿n.

## 2. Thiáº¿t Láº­p Dá»± Ãn ğŸ”§

Tiáº¿p theo, chÃºng ta thiáº¿t láº­p dá»± Ã¡n báº±ng cÃ¡ch cáº¥u hÃ¬nh cÃ¡c API key cáº§n thiáº¿t. á» Ä‘Ã¢y, báº¡n sáº½ cáº§n key tá»« **Google API** vÃ  **Tavily API** (Ä‘á»ƒ thá»±c hiá»‡n tÃ¬m kiáº¿m trÃªn web). MÃ¬nh sá»­ dá»¥ng `getpass` Ä‘á»ƒ nháº­p key má»™t cÃ¡ch báº£o máº­t:

```python
import os
import getpass

if "GOOGLE_API_KEY" not in os.environ:
  os.environ["GOOGLE_API_KEY"] = getpass.getpass("Enter your Google API Key: ")

if "TAVILY_API_KEY" not in os.environ:
  os.environ["TAVILY_API_KEY"] = getpass.getpass("Enter your Google API Key: ")

```

Báº¡n cÃ³ thá»ƒ truy cáº­p vÃ o [Ä‘Ã¢y](https://app.tavily.com/home?code=SAWcRNUWjLA-9FLWcohdGmAp4xOfPJu4lvIEmevo6px0e&state=eyJyZXR1cm5UbyI6Ii9ob21lIn0) Ä‘á»ƒ láº¥y API key cho Tavily. Äá»‘i vá»›i Google API key thÃ¬ cÃ¡c báº¡n vÃ o Google AI Studio nha (CÃ¡i nÃ y Ä‘Ã£ Ä‘Æ°á»£c giá»›i thiá»‡u trong cÃ¡c dá»± Ã¡n trÆ°á»›c rá»“i nÃ¨)

## 3. Khá»Ÿi Táº¡o LLM vá»›i Google Generative AI ğŸŒŸ

Trong pháº§n nÃ y, chÃºng ta sá»­ dá»¥ng thÆ° viá»‡n `langchain_google_genai` Ä‘á»ƒ khá»Ÿi táº¡o má»™t mÃ´ hÃ¬nh LLM (Large Language Model) tá»« Google. Hiá»‡n nay, Google Ä‘Ã£ phÃ¡t hÃ nh Gemini 2.0 vá»›i nhiá»u tÃ­nh nÄƒng má»›i. Cáº¥u hÃ¬nh mÃ´ hÃ¬nh nhÆ° sau:

```python
from langchain_google_genai import ChatGoogleGenerativeAI

llm = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash",
    temperature=0.7,
    max_tokens=None,
    timeout=None,
    max_retries=2,
)
print("Initialized LLM successfully!")
```

Sau Ä‘Ã³, chÃºng ta káº¿t há»£p mÃ´ hÃ¬nh nÃ y vá»›i cÃ´ng cá»¥ tÃ¬m kiáº¿m cá»§a Tavily:

```python
from langchain_community.tools.tavily_search import TavilySearchResults

tools = [TavilySearchResults(max_results=1)]
model_with_tool = llm.bind_tools(tools)

```

Viá»‡c bind tools giÃºp mÃ´ hÃ¬nh khÃ´ng chá»‰ tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n mÃ  cÃ²n cÃ³ thá»ƒ truy váº¥n dá»¯ liá»‡u má»›i tá»« internet khi cáº§n thiáº¿t.

## 4. Äá»‹nh NghÄ©a State cho Agent ğŸ—‚

Äá»ƒ theo dÃµi tráº¡ng thÃ¡i cá»§a Agent trong quÃ¡ trÃ¬nh tÆ°Æ¡ng tÃ¡c, chÃºng ta Ä‘á»‹nh nghÄ©a má»™t kiá»ƒu dá»¯ liá»‡u `AgentState`. Kiá»ƒu dá»¯ liá»‡u nÃ y chá»©a danh sÃ¡ch cÃ¡c message Ä‘Ã£ Ä‘Æ°á»£c trao Ä‘á»•i:

```python
from typing import TypedDict, Annotated, Sequence
from langchain_core.messages import BaseMessage
import operator

class AgentState(TypedDict):
  messages: Annotated[Sequence[BaseMessage], operator.add]
```

## 5. Khá»Ÿi Táº¡o CÃ¡c Node cá»§a Workflow ğŸ”„

ChÃ­nh nhá» LangGraph, chÃºng ta cÃ³ thá»ƒ xÃ¢y dá»±ng má»™t workflow rÃµ rÃ ng vá»›i cÃ¡c node thá»±c hiá»‡n cÃ¡c bÆ°á»›c khÃ¡c nhau trong quÃ¡ trÃ¬nh xá»­ lÃ½ yÃªu cáº§u cá»§a ngÆ°á»i dÃ¹ng. á» Ä‘Ã¢y, cÃ³ hai node chÃ­nh:

1. **Tool Node**: Node nÃ y sá»­ dá»¥ng `TavilySearchResults` Ä‘á»ƒ truy xuáº¥t dá»¯ liá»‡u.
2. **Tool Invocation**: Node gá»i mÃ´ hÃ¬nh LLM vá»›i tráº¡ng thÃ¡i hiá»‡n táº¡i vÃ  nháº­n káº¿t quáº£ pháº£n há»“i.

Äoáº¡n code dÆ°á»›i Ä‘Ã¢y Ä‘á»‹nh nghÄ©a hÃ m kiá»ƒm tra xem liá»‡u workflow cÃ³ cáº§n tiáº¿p tá»¥c hay dá»«ng láº¡i:

```python
def should_continue(state):
  messages = state["messages"]
  last_message = messages[-1]

  if last_message.tool_calls:
    return "continue"
  else:
    return "end"
```

VÃ  hÃ m gá»i mÃ´ hÃ¬nh:

```python
def call_model(state):
  messages = state["messages"]
  response = model_with_tool.invoke(messages)
  return {"messages": [response]}
```

## 6. Äá»‹nh NghÄ©a WorkFlow cá»§a Agent ğŸ•¸

BÃ¢y giá», chÃºng ta sáº½ Ä‘á»‹nh nghÄ©a workflow cho Agent báº±ng cÃ¡ch sá»­ dá»¥ng **StateGraph** tá»« LangGraph. Workflow nÃ y cho phÃ©p chuyá»ƒn Ä‘á»•i linh hoáº¡t giá»¯a cÃ¡c node dá»±a trÃªn káº¿t quáº£ tráº£ vá» tá»« LLM vÃ  cÃ¡c tool:

```python
from langgraph.graph import StateGraph, START, END

workflow = StateGraph(AgentState)

workflow.add_node("agent", call_model)
workflow.add_node("action", tool_node)

workflow.set_entry_point("agent")
workflow.add_conditional_edges(
    "agent",
    should_continue,
    {
        "continue": "action",
        "end": END
    }
)
workflow.add_edge("action", "agent")

app = workflow.compile()
```

Qua Ä‘Ã³, luá»“ng xá»­ lÃ½ Ä‘Æ°á»£c hÃ¬nh thÃ nh theo logic:

**Human â†’ LLM â†’ Tool â†’ LLM â†’ Response**

NgoÃ i ra, chÃºng ta cÃ²n trá»±c quan hÃ³a workflow thÃ´ng qua biá»ƒu Ä‘á»“ Mermaid Ä‘á»ƒ cÃ³ cÃ¡i nhÃ¬n tá»•ng quÃ¡t vá» quÃ¡ trÃ¬nh:

```python
from langchain_core.runnables.graph import MermaidDrawMethod
from IPython.display import display, Image

display(
    Image(app.get_graph().draw_mermaid_png(
        draw_method=MermaidDrawMethod.API
    ))
)

```

## 7. Thá»­ Nghiá»‡m WorkFlow vÃ  Hiá»ƒn Thá»‹ Quy TrÃ¬nh ğŸš€

Cuá»‘i cÃ¹ng, chÃºng ta thá»±c hiá»‡n thá»­ nghiá»‡m workflow báº±ng cÃ¡ch gá»­i má»™t cÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng. VÃ­ dá»¥, cÃ¢u há»i "What is the weather in Hue city?" sáº½ Ä‘Æ°á»£c gá»­i qua hÃ m `call_app` vÃ  káº¿t quáº£ tráº£ vá» Ä‘Æ°á»£c in ra:

```python
from langchain_core.messages import HumanMessage

def call_app(content):
  inputs = {"messages": [HumanMessage(content=content)]}
  results = app.invoke(inputs)
  return results["messages"][-1].content, results["messages"]

last_response, messages = call_app("What is the weather in Hue city?")
print(last_response)

```

---

## Káº¿t Luáº­n ğŸ’¡

Trong bÃ i viáº¿t nÃ y, chÃºng ta Ä‘Ã£ cÃ¹ng nhau xÃ¢y dá»±ng má»™t AI Agent Ä‘Æ¡n giáº£n sá»­ dá»¥ng cÃ¡c cÃ´ng cá»¥ máº¡nh máº½ tá»« LangChain vÃ  LangGraph. Qua Ä‘Ã³, ta khÃ´ng chá»‰ há»c cÃ¡ch khá»Ÿi táº¡o vÃ  cáº¥u hÃ¬nh mÃ´ hÃ¬nh LLM tá»« Google mÃ  cÃ²n náº¯m báº¯t Ä‘Æ°á»£c quy trÃ¬nh xÃ¢y dá»±ng má»™t workflow linh hoáº¡t, cÃ³ kháº£ nÄƒng má»Ÿ rá»™ng theo cÃ¡c nhu cáº§u cá»¥ thá»ƒ.

Viá»‡c sá»­ dá»¥ng workflow theo dáº¡ng **Human â†’ LLM â†’ Tool â†’ LLM â†’ Response** giÃºp ta táº¡o ra cÃ¡c á»©ng dá»¥ng AI cÃ³ kháº£ nÄƒng tÆ°Æ¡ng tÃ¡c tá»± nhiÃªn vÃ  hiá»‡u quáº£, Ä‘á»“ng thá»i dá»… dÃ ng tÃ­ch há»£p thÃªm nhiá»u cÃ´ng cá»¥ khÃ¡c nhau Ä‘á»ƒ má»Ÿ rá»™ng chá»©c nÄƒng. ToÃ n bá»™ mÃ£ nguá»“n Ä‘Æ°á»£c triá»ƒn khai táº¡i: [https://colab.research.google.com/drive/13M7D2Vqa469Vybf_7HGu2ehwOuFlvBD1?usp=sharing](https://colab.research.google.com/drive/13M7D2Vqa469Vybf_7HGu2ehwOuFlvBD1?usp=sharing)

---

ğŸŒŸ Náº¿u báº¡n tháº¥y bÃ i viáº¿t nÃ y há»¯u Ã­ch, Ä‘á»«ng quÃªn Ä‘á»ƒ láº¡i má»™t â­ trÃªn repo cá»§a tÃ¡c giáº£ nhÃ©!

**TÃ¡c giáº£:** Trung LÃª

ğŸ“§ **Email:** lebaquoctrung@gmail.com

ğŸ’» **GitHub:** [LBQTrung](https://github.com/LBQTrung)

ğŸŒ **Website:** [lbqtrung.github.io](https://lbqtrung.github.io/)
